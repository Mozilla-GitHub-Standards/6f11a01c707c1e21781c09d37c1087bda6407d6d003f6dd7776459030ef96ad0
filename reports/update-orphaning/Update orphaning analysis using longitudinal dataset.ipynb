{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update orphaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import urllib2\n",
    "import ujson as json\n",
    "from os import environ\n",
    "\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the time when this job was started (for debugging purposes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "starttime = dt.datetime.now()\n",
    "starttime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declare the channel to look at."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "channel_to_process = \"release\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sc.defaultParallelism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Uncomment the next line and adjust |today_env_str| as necessary to run manually\n",
    "#today_env_str = \"20161105\"\n",
    "today_env_str = environ.get(\"date\", None)\n",
    "\n",
    "assert (today_env_str is not None), \"The date environment parameter is missing.\"\n",
    "today = dt.datetime.strptime(today_env_str, \"%Y%m%d\").date()\n",
    "\n",
    "# Find the date of last Wednesday to get the proper 7 day range\n",
    "last_wednesday = today\n",
    "current_weekday = today.weekday()\n",
    "if (current_weekday < 2):\n",
    "    last_wednesday -= (dt.timedelta(days=5) + dt.timedelta(days=current_weekday))\n",
    "if (current_weekday > 2):\n",
    "    last_wednesday -= (dt.timedelta(days=current_weekday) - dt.timedelta(days=2))\n",
    "\n",
    "min_range = last_wednesday - dt.timedelta(days=17)\n",
    "report_date_str = last_wednesday.strftime(\"%Y%m%d\")\n",
    "min_range_str = min_range.strftime(\"%Y%m%d\")\n",
    "min_range_dash_str = min_range.strftime(\"%Y-%m-%d\")\n",
    "list([last_wednesday, min_range_str, report_date_str])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The longitudinal dataset can be accessed as a Spark [DataFrame](https://spark.apache.org/docs/1.5.2/api/python/pyspark.sql.html#pyspark.sql.DataFrame), which is a distributed collection of data organized into named columns. It is conceptually equivalent to a table in a relational database or a data frame in R/Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sql_str = \"SELECT * FROM longitudinal_v\" + today_env_str\n",
    "frame = sqlContext.sql(sql_str)\n",
    "sql_str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restrict the dataframe to the desired channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "channel_subset = frame.filter(frame.normalized_channel == channel_to_process)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restrict the dataframe to the desired data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_subset = channel_subset.select(\"subsession_start_date\",\n",
    "                                    \"subsession_length\",\n",
    "                                    \"update_check_code_notify\",\n",
    "                                    \"update_check_no_update_notify\",\n",
    "                                    \"build.version\",\n",
    "                                    \"settings.update.enabled\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restrict the data to the proper 7 day range, starting at least 17 days before the creation date of the\n",
    "longitudinal dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def start_date_filter(d):\n",
    "    try:\n",
    "        date = dt.datetime.strptime(d.subsession_start_date[0][:10], \"%Y-%m-%d\").date()\n",
    "        return min_range <= date\n",
    "    except ValueError:\n",
    "        return False\n",
    "    except TypeError:\n",
    "        return False\n",
    "\n",
    "date_filtered = data_subset.rdd.filter(start_date_filter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyze the data to determine the number of users on a current version of Firefox vs. a version that's out of date. A \"user on a current version\" is defined as being either on the latest version as of the beginning of the 7 day range, according to the firefox_history_major_releases.json file on product-details.mozilla.org, or the two versions just prior to it. Versions prior to FF 42 are ignored since unified telemetry was not turned on by default on earlier versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def latest_version_on_date(date, major_releases):\n",
    "    latest_date, latest_version = u\"1900-01-01\", 0\n",
    "    for version, release_date in major_releases.iteritems():\n",
    "        version_int = int(version.split(\".\")[0])\n",
    "        if release_date <= date and release_date >= latest_date and version_int >= latest_version:\n",
    "            latest_date = release_date\n",
    "            latest_version = version_int\n",
    "            \n",
    "    return latest_version\n",
    "    \n",
    "major_releases_json = urllib2.urlopen(\"https://product-details.mozilla.org/1.0/firefox_history_major_releases.json\").read()\n",
    "major_releases = json.loads(major_releases_json)\n",
    "latest_version = latest_version_on_date(min_range_dash_str, major_releases)\n",
    "\n",
    "def status_mapper(d):\n",
    "    try:\n",
    "        if d.version is None or d.version[0] is None:\n",
    "            return (\"none-version\", d)\n",
    "        curr_version = int(d.version[0].split(\".\")[0])\n",
    "        if curr_version < 42:\n",
    "            return (\"ignore-version-too-low\", d)\n",
    "        if curr_version < latest_version - 2:\n",
    "            # Check if the user ran a particular orphaned version of Firefox for at least 2 hours in\n",
    "            # the last 12 weeks. An orphaned user is running a version of Firefox that's at least 3\n",
    "            # versions behind the current version. This means that an update has been available for\n",
    "            # at least 12 weeks. 2 hours so most systems have had a chance to perform an update\n",
    "            # check, download the update, and restart Firefox after the update has been downloaded.\n",
    "            seconds = 0\n",
    "            curr_version = d.version[0]\n",
    "            index = 0\n",
    "            twelve_weeks_ago = last_wednesday - dt.timedelta(weeks=12)\n",
    "            while seconds < 7200 and index < len(d.version) and d.version[index] == curr_version:\n",
    "                try:\n",
    "                    date = dt.datetime.strptime(d.subsession_start_date[index][:10], \"%Y-%m-%d\").date()\n",
    "                    if date < twelve_weeks_ago:\n",
    "                        return (\"out-of-date-not-run-long-enough\", d)\n",
    "                    seconds += d.subsession_length[index]\n",
    "                    index += 1\n",
    "                except ValueError:\n",
    "                    index += 1\n",
    "                except TypeError:\n",
    "                    index += 1\n",
    "            if seconds >= 7200:\n",
    "                return (\"out-of-date\", d)\n",
    "            return (\"out-of-date-not-run-long-enough\", d)\n",
    "        return (\"up-to-date\", d)\n",
    "    except ValueError:\n",
    "        return (\"value-error\", d)\n",
    "        \n",
    "statuses = date_filtered.map(status_mapper).cache()\n",
    "up_to_date_results = statuses.countByKey()\n",
    "up_to_date_json_results = json.dumps(up_to_date_results, ensure_ascii=False)\n",
    "up_to_date_json_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For people who are out-of-date, determine how many of them have updates disabled:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "out_of_date_statuses = statuses.filter(lambda p: \"out-of-date\" in p)\n",
    "\n",
    "def update_disabled_mapper(d):\n",
    "    status, ping = d\n",
    "    if ping is None or ping.enabled is None or ping.enabled[0] is None:\n",
    "        return (\"none-update-enabled\", ping)\n",
    "    if ping.enabled[0] == True:\n",
    "        return (\"update-enabled\", ping)\n",
    "    return (\"update-disabled\", ping)\n",
    "    \n",
    "update_enabled_disabled_statuses = out_of_date_statuses.map(update_disabled_mapper)\n",
    "update_enabled_disabled_results = update_enabled_disabled_statuses.countByKey()\n",
    "update_enabled_disabled_json_results = json.dumps(update_enabled_disabled_results, ensure_ascii=False)\n",
    "update_enabled_disabled_json_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Focus on orphaned users who have updates enabled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "update_enabled_statuses = update_enabled_disabled_statuses.filter(lambda p: \"update-enabled\" in p).cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For people who are out-of-date and have updates enabled, determine the distribution across Firefox versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def version_mapper(d):\n",
    "    status, ping = d\n",
    "    return (ping.version[0], ping)\n",
    "    \n",
    "orphaned_by_versions = update_enabled_statuses.map(version_mapper)\n",
    "orphaned_by_versions_results = orphaned_by_versions.countByKey()\n",
    "orphaned_by_versions_json_results = json.dumps(orphaned_by_versions_results, ensure_ascii=False)\n",
    "orphaned_by_versions_json_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For people who are out-of-date and have updates enabled, determine what the update check returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def update_check_code_notify_mapper(d):\n",
    "    status, ping = d\n",
    "    if ping is None or ping.update_check_code_notify is None:\n",
    "        return -1\n",
    "    for check_code in ping.update_check_code_notify:\n",
    "        counter = -1\n",
    "        for i in check_code:\n",
    "            counter += 1\n",
    "            if i != 0:\n",
    "                return counter\n",
    "    if ping.update_check_no_update_notify is not None and ping.update_check_no_update_notify[0] > 0:\n",
    "        return 0;\n",
    "    return -1\n",
    "\n",
    "update_check_code_notify_statuses = update_enabled_statuses.map(update_check_code_notify_mapper)\n",
    "update_check_code_notify_results = update_check_code_notify_statuses.countByValue()\n",
    "update_check_code_notify_json_results = json.dumps(update_check_code_notify_results, ensure_ascii=False)\n",
    "update_check_code_notify_json_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write results to JSON."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "latest_version_object = {\"latest-version\": latest_version}\n",
    "up_to_date_object = {\"up-to-date\": up_to_date_results}\n",
    "update_enabled_disabled_object = {\"update-enabled-disabled\": update_enabled_disabled_results}\n",
    "update_check_code_notify_object = {\"update-check-code-notify\": update_check_code_notify_results}\n",
    "orphaned_by_versions_object = {\"orphaned-by-versions\": orphaned_by_versions_results}\n",
    "\n",
    "final_results = [up_to_date_object, update_enabled_disabled_object, update_check_code_notify_object, latest_version_object, orphaned_by_versions_object]\n",
    "final_results_json =  json.dumps(final_results, ensure_ascii=False)\n",
    "final_results_json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, store the output in the local directory to be uploaded automatically once the job completes. The file will be stored at:\n",
    "\n",
    "https://analysis-output.telemetry.mozilla.org/SPARKJOBNAME/data/FILENAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filename = \"./output/\" + report_date_str + \".json\"\n",
    "\n",
    "with open(filename, 'w') as f:\n",
    "    f.write(final_results_json)\n",
    "\n",
    "filename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the time when this job ended (for debugging purposes):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "endtime = dt.datetime.now()\n",
    "endtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "difference = endtime - starttime\n",
    "difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
